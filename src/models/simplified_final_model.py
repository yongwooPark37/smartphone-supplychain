# src/models/simplified_final_model.py
# ë‹¨ìˆœí™”ëœ ìµœì¢… ëª¨ë¸ - í•µì‹¬ í”¼ì²˜ë§Œ ì‚¬ìš©

import pandas as pd
import numpy as np
import sqlite3
from pathlib import Path
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# ê²½ë¡œ ì„¤ì •
SCRIPT = Path(__file__).resolve()
PROJECT_ROOT = SCRIPT.parents[2]
DATA_DIR = PROJECT_ROOT / "data"

def get_country_mapping():
    """êµ­ê°€ ë§¤í•‘"""
    return {
        'Washington_DC':'USA','New_York':'USA','Chicago':'USA','Dallas':'USA',
        'Berlin':'DEU','Munich':'DEU','Frankfurt':'DEU','Hamburg':'DEU',
        'Paris':'FRA','Lyon':'FRA','Marseille':'FRA','Toulouse':'FRA',
        'Seoul':'KOR','Busan':'KOR','Incheon':'KOR','Gwangju':'KOR',
        'Tokyo':'JPN','Osaka':'JPN','Nagoya':'JPN','Fukuoka':'JPN',
        'Manchester':'GBR','London':'GBR','Birmingham':'GBR','Glasgow':'GBR',
        'Ottawa':'CAN','Toronto':'CAN','Vancouver':'CAN','Montreal':'CAN',
        'Canberra':'AUS','Sydney':'AUS','Melbourne':'AUS','Brisbane':'AUS',
        'Brasilia':'BRA','Sao_Paulo':'BRA','Rio_de_Janeiro':'BRA','Salvador':'BRA',
        'Pretoria':'ZAF','Johannesburg':'ZAF','Cape_Town':'ZAF','Durban':'ZAF'
    }

def get_event_multipliers():
    """ì‹¤ì œ ê³¼ê±° ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ë°°ìˆ˜"""
    return {
        '2023': {
            'CAN': ('2023-09-01', '2023-11-30', 2.57),
            'DEU': ('2023-11-01', '2023-12-31', 2.30),
            'BRA': ('2023-10-01', '2023-12-31', 2.34),
        },
        '2024': {
            'DEU': ('2024-07-01', '2024-09-30', 2.30),
            'JPN': ('2024-07-01', '2024-09-30', 2.21),
            'GBR': ('2024-07-01', '2024-09-30', 2.39),
        }
    }

def load_training_data():
    """í•™ìŠµ ë°ì´í„° ë¡œë“œ (í•µì‹¬ í”¼ì²˜ë§Œ)"""
    # ìˆ˜ìš” ë°ì´í„°
    conn = sqlite3.connect(DATA_DIR / "demand_train_processed.db")
    demand = pd.read_sql("SELECT * FROM demand_train", conn, parse_dates=['date'])
    conn.close()
    
    # êµ­ê°€ ë§¤í•‘ ì¶”ê°€
    country_map = get_country_mapping()
    demand["country"] = demand["city"].map(country_map)
    
    # í•µì‹¬ ì‹œê°„ í”¼ì²˜ë§Œ
    demand["year"] = demand["date"].dt.year
    demand["month"] = demand["date"].dt.month
    demand["dayofyear"] = demand["date"].dt.dayofyear
    demand["weekday"] = demand["date"].dt.weekday
    demand["quarter"] = demand["date"].dt.quarter
    
    # ê³„ì ˆ ì •ë³´ ì¶”ê°€ (calendar.csvì—ì„œ)
    calendar = pd.read_csv(DATA_DIR / "calendar.csv", parse_dates=["date"])
    demand = demand.merge(calendar[["date", "country", "season"]], on=["date", "country"], how="left")
    
    # SKU ë©”íƒ€ ì •ë³´
    sku_meta = pd.read_csv(DATA_DIR / "sku_meta.csv", parse_dates=["launch_date"])
    demand = demand.merge(sku_meta[["sku", "family", "storage_gb", "launch_date"]], on="sku", how="left")
    demand["days_since_launch"] = (demand["date"] - demand["launch_date"]).dt.days.clip(lower=0)
    
    # í•µì‹¬ ì‹œê³„ì—´ í”¼ì²˜ë§Œ
    demand = demand.sort_values(["city", "sku", "date"])
    
    # ì£¼ìš” ë™ í”¼ì²˜ë§Œ
    for lag in [7, 30]:
        demand[f"demand_lag_{lag}"] = demand.groupby(["city", "sku"])["demand"].shift(lag).fillna(0)
    
    # ê°„ë‹¨í•œ ë¡¤ë§ í‰ê· ë§Œ
    demand["demand_rolling_mean_7"] = demand.groupby(["city", "sku"])["demand"].transform(lambda x: x.rolling(window=7, min_periods=1).mean())
    
    # ë„ì‹œë³„ í‰ê·  ìˆ˜ìš” (ê¸°ì¤€ê°’)
    city_sku_avg = demand.groupby(["city", "sku"])["demand"].mean().reset_index()
    city_sku_avg = city_sku_avg.rename(columns={"demand": "city_sku_avg_demand"})
    demand = demand.merge(city_sku_avg, on=["city", "sku"], how="left")
    
    return demand

def train_simplified_model(train_data):
    """ë‹¨ìˆœí™”ëœ ëª¨ë¸ í•™ìŠµ"""
    train_mask = train_data["year"] <= 2021
    val_mask = train_data["year"] == 2022
    
    train_set = train_data[train_mask].copy()
    val_set = train_data[val_mask].copy()
    
    # í•µì‹¬ í”¼ì²˜ë§Œ ì„ íƒ
    feature_cols = [
        "city", "sku", "country", "family", 
        "season", "month", "quarter", "dayofyear", "weekday", "storage_gb",
        "days_since_launch", 
        "demand_lag_7", "demand_lag_30",
        "demand_rolling_mean_7",
        "city_sku_avg_demand"
    ]
    
    # ë²”ì£¼í˜• ì¸ì½”ë”©
    label_encoders = {}
    for col in ["city", "sku", "country", "family", "season"]:
        le = LabelEncoder()
        train_set[col + "_encoded"] = le.fit_transform(train_set[col].astype(str))
        val_set[col + "_encoded"] = le.transform(val_set[col].astype(str))
        label_encoders[col] = le
        feature_cols.append(col + "_encoded")
        feature_cols.remove(col)
    
    # ëª¨ë¸ í•™ìŠµ - ë‹¨ìˆœí™”ëœ íŒŒë¼ë¯¸í„°
    X_train = train_set[feature_cols]
    y_train = train_set["demand"]
    
    model = RandomForestRegressor(
        n_estimators=100,  # íŠ¸ë¦¬ ìˆ˜ ì¤„ì„
        max_depth=10,      # ê¹Šì´ ì¤„ì„
        min_samples_split=10,  # ë¶„í•  ê¸°ì¤€ ê°•í™”
        min_samples_leaf=5,    # ë¦¬í”„ ë…¸ë“œ ìµœì†Œ ìƒ˜í”Œ ê°•í™”
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train, y_train)
    
    # ê²€ì¦
    X_val = val_set[feature_cols]
    y_val = val_set["demand"]
    val_pred = model.predict(X_val)
    
    from sklearn.metrics import mean_squared_error, r2_score
    rmse = np.sqrt(mean_squared_error(y_val, val_pred))
    r2 = r2_score(y_val, val_pred)
    
    print(f"Simplified Model - Validation RMSE: {rmse:.2f}")
    print(f"Simplified Model - Validation RÂ²: {r2:.3f}")
    
    # ê³¼ì†Œí‰ê°€ ë¬¸ì œ ì§„ë‹¨
    print(f"\n=== Bias Analysis ===")
    print(f"Actual mean: {y_val.mean():.2f}")
    print(f"Predicted mean: {val_pred.mean():.2f}")
    print(f"Bias: {val_pred.mean() - y_val.mean():.2f}")
    print(f"Relative bias: {((val_pred.mean() - y_val.mean()) / y_val.mean() * 100):.1f}%")
    
    # í”¼ì²˜ ì¤‘ìš”ë„
    importance_df = pd.DataFrame({
        "feature": X_train.columns,
        "importance": model.feature_importances_
    }).sort_values("importance", ascending=False)
    
    print("\n=== Top 10 Feature Importance ===")
    print(importance_df.head(10))
    
    # 2022 ê²€ì¦ ê²°ê³¼ ì‹œê°í™”
    visualize_2022_validation(val_set, val_pred, r2)
    
    return model, label_encoders, feature_cols

def visualize_2022_validation(val_set, val_pred, r2_score):
    """2022 ê²€ì¦ ê²°ê³¼ ì‹œê°í™”"""
    
    # val_predë¥¼ val_setê³¼ ê°™ì€ ìˆœì„œë¡œ ì •ë ¬
    val_set_with_pred = val_set.copy()
    val_set_with_pred["predicted"] = val_pred
    
    # ì¼ë³„ ì´ ìˆ˜ìš” ì§‘ê³„
    daily_actual = val_set_with_pred.groupby("date")["demand"].sum().reset_index()
    daily_pred = val_set_with_pred.groupby("date")["predicted"].sum().reset_index()
    
    # ë°ì´í„° ë³‘í•©
    comparison = daily_actual.merge(daily_pred, on="date", suffixes=("", "_pred"))
    comparison = comparison.rename(columns={"predicted": "predicted"})
    
    # ì‹œê°í™” - í•˜ë‚˜ì˜ ê·¸ë˜í”„ë§Œ
    plt.figure(figsize=(12, 6))
    plt.plot(comparison["date"], comparison["demand"], label="Actual", alpha=0.8, linewidth=2, color='blue')
    plt.plot(comparison["date"], comparison["predicted"], label="Predicted", alpha=0.8, linewidth=2, color='red')
    plt.title(f"2022 Daily Demand: Actual vs Predicted (RÂ² = {r2_score:.3f})")
    plt.xlabel("Date")
    plt.ylabel("Daily Total Demand")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()

def generate_simplified_forecast():
    """ë‹¨ìˆœí™”ëœ ì˜ˆì¸¡ ìƒì„±"""
    print("Loading training data...")
    train_data = load_training_data()
    
    print("Training simplified model...")
    model, label_encoders, feature_cols = train_simplified_model(train_data)
    
    print("Generating forecast...")
    
    # 2023-2024 ì˜ˆì¸¡ ë°ì´í„° ìƒì„±
    future_dates = pd.date_range(start="2023-01-01", end="2024-12-31", freq="D")
    future_df = pd.DataFrame({"date": future_dates})
    
    # ë¯¸ë˜ ë°ì´í„°ì— í”¼ì²˜ ì¶”ê°€
    future_df["year"] = future_df["date"].dt.year
    future_df["month"] = future_df["date"].dt.month
    future_df["dayofyear"] = future_df["date"].dt.dayofyear
    future_df["weekday"] = future_df["date"].dt.weekday
    future_df["quarter"] = future_df["date"].dt.quarter
    
    # ê³„ì ˆ ì •ë³´ ì¶”ê°€
    calendar = pd.read_csv(DATA_DIR / "calendar.csv", parse_dates=["date"])
    future_df = future_df.merge(calendar[["date", "country", "season"]], on="date", how="left")
    
    # SKU ì •ë³´ ì¶”ê°€
    sku_meta = pd.read_csv(DATA_DIR / "sku_meta.csv", parse_dates=["launch_date"])
    
    # ëª¨ë“  ë„ì‹œì™€ SKU ì¡°í•© ìƒì„±
    cities = train_data["city"].unique()
    skus = train_data["sku"].unique()
    
    results = []
    events = get_event_multipliers()
    
    for city in cities:
        country = get_country_mapping()[city]
        
        for sku in skus:
            sku_info = sku_meta[sku_meta["sku"] == sku].iloc[0]
            
            # í•´ë‹¹ SKUì˜ ë¯¸ë˜ ë°ì´í„° ìƒì„±
            sku_future = future_df.copy()
            sku_future["city"] = city
            sku_future["country"] = country
            sku_future["sku"] = sku
            sku_future["family"] = sku_info["family"]
            sku_future["storage_gb"] = sku_info["storage_gb"]
            sku_future["launch_date"] = sku_info["launch_date"]
            sku_future["days_since_launch"] = (sku_future["date"] - sku_future["launch_date"]).dt.days.clip(lower=0)
            
            # ê³¼ê±° ë°ì´í„°ì—ì„œ í•´ë‹¹ SKUì˜ ìµœê·¼ ìˆ˜ìš” ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            sku_history = train_data[(train_data["city"] == city) & (train_data["sku"] == sku)].sort_values("date")
            
            if len(sku_history) > 0:
                # ìµœê·¼ ìˆ˜ìš”ê°’ë“¤ë¡œ ë¯¸ë˜ ì˜ˆì¸¡ì„ ìœ„í•œ í”¼ì²˜ ìƒì„±
                recent_demand = sku_history["demand"].iloc[-1] if len(sku_history) > 0 else 0
                recent_lag_7 = sku_history["demand"].iloc[-7] if len(sku_history) >= 7 else recent_demand
                recent_lag_30 = sku_history["demand"].iloc[-30] if len(sku_history) >= 30 else recent_demand
                recent_rolling_mean = sku_history["demand"].tail(7).mean() if len(sku_history) >= 7 else recent_demand
                city_sku_avg = sku_history["demand"].mean()
            else:
                # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ê°’
                recent_demand = 0
                recent_lag_7 = 0
                recent_lag_30 = 0
                recent_rolling_mean = 0
                city_sku_avg = 0
            
            # ë¯¸ë˜ ë°ì´í„°ì— ê³¼ê±° ì •ë³´ ì ìš©
            sku_future["demand"] = recent_demand
            sku_future["demand_lag_7"] = recent_lag_7
            sku_future["demand_lag_30"] = recent_lag_30
            sku_future["demand_rolling_mean_7"] = recent_rolling_mean
            sku_future["city_sku_avg_demand"] = city_sku_avg
            
            # ë²”ì£¼í˜• ì¸ì½”ë”©
            for col in ["city", "sku", "country", "family", "season"]:
                le = label_encoders[col]
                sku_future[col + "_encoded"] = le.transform(sku_future[col].astype(str))
            
            # ëª¨ë¸ ì˜ˆì¸¡
            X_future = sku_future[feature_cols]
            base_pred = model.predict(X_future)
            
            # ì´ë²¤íŠ¸ ë°°ìˆ˜ ì ìš©
            for date, pred in zip(sku_future["date"], base_pred):
                event_multiplier = 1.0
                
                # ì´ë²¤íŠ¸ í™•ì¸
                for year, year_events in events.items():
                    for event_country, (start_date, end_date, multiplier) in year_events.items():
                        if (event_country == country and 
                            pd.to_datetime(start_date) <= date <= pd.to_datetime(end_date)):
                            event_multiplier = multiplier
                            break
                
                adjusted_pred = pred * event_multiplier
                
                results.append({
                    "date": date.strftime("%Y-%m-%d"),
                    "sku": sku,
                    "city": city,
                    "mean": int(max(adjusted_pred, 0))
                })
    
    # ê²°ê³¼ ì €ì¥
    result_df = pd.DataFrame(results)
    output_path = DATA_DIR / "simplified_forecast_submission.csv"
    result_df.to_csv(output_path, index=False)
    
    print(f"âœ… Simplified forecast saved: {output_path}")
    print(f"Total predictions: {len(result_df):,}")
    print(f"Average demand: {result_df['mean'].mean():.1f}")
    print(f"Max demand: {result_df['mean'].max():,}")
    print(f"Min demand: {result_df['mean'].min()}")
    
    return result_df

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    print("=== Simplified Final Forecast Model ===\n")
    
    result_df = generate_simplified_forecast()
    
    print(f"\nâœ… ë‹¨ìˆœí™”ëœ ìµœì¢… ëª¨ë¸ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ íŒŒì¼: simplified_forecast_submission.csv")

if __name__ == "__main__":
    main() 