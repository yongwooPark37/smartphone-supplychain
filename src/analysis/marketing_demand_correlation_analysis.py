"""
ë§ˆì¼€íŒ… ì§€ì¶œê³¼ ìˆ˜ìš” ê¸‰ë“±ì˜ ìƒê´€ê´€ê³„ ë¶„ì„
ì¶œì œìì˜ "ë§ˆì¼€íŒ… ì§€ì¶œ = ì´ë²¤íŠ¸" ê°€ì •ì„ ê²€ì¦í•˜ëŠ” ì½”ë“œ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# matplotlib ë°±ì—”ë“œ ì„¤ì • (GUI ì—†ì´ ì‹¤í–‰)
plt.switch_backend('Agg')

# ë°ì´í„° ê²½ë¡œ
DATA_DIR = Path("C:/projects/smartphone-supplychain/data")

def load_data():
    """ëª¨ë“  ë°ì´í„° ë¡œë“œ"""
    print("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")
    
    # ìˆ˜ìš” ë°ì´í„° (SQLite ë°ì´í„°ë² ì´ìŠ¤)
    import sqlite3
    conn = sqlite3.connect(DATA_DIR / "demand_train.db")
    demand = pd.read_sql_query("SELECT * FROM demand_train", conn)
    conn.close()
    demand['date'] = pd.to_datetime(demand['date'])
    
    # ë§ˆì¼€íŒ… ì§€ì¶œ ë°ì´í„°
    marketing = pd.read_csv(DATA_DIR / "marketing_spend.csv", parse_dates=["date"])
    
    # êµ­ê°€ ë§¤í•‘
    country_map = {
        'Seoul': 'KOR', 'Busan': 'KOR', 'Incheon': 'KOR', 'Daegu': 'KOR', 'Daejeon': 'KOR',
        'Gwangju': 'KOR', 'Suwon': 'KOR', 'Ulsan': 'KOR', 'Seongnam': 'KOR', 'Bucheon': 'KOR',
        'Tokyo': 'JPN', 'Yokohama': 'JPN', 'Osaka': 'JPN', 'Nagoya': 'JPN', 'Sapporo': 'JPN',
        'Fukuoka': 'JPN', 'Kobe': 'JPN', 'Kyoto': 'JPN', 'Kawasaki': 'JPN', 'Saitama': 'JPN',
        'New York': 'USA', 'Los Angeles': 'USA', 'Chicago': 'USA', 'Houston': 'USA', 'Phoenix': 'USA',
        'Philadelphia': 'USA', 'San Antonio': 'USA', 'San Diego': 'USA', 'Dallas': 'USA', 'San Jose': 'USA',
        'London': 'GBR', 'Birmingham': 'GBR', 'Leeds': 'GBR', 'Glasgow': 'GBR', 'Sheffield': 'GBR',
        'Bradford': 'GBR', 'Edinburgh': 'GBR', 'Liverpool': 'GBR', 'Manchester': 'GBR', 'Bristol': 'GBR',
        'Berlin': 'DEU', 'Hamburg': 'DEU', 'Munich': 'DEU', 'Cologne': 'DEU', 'Frankfurt': 'DEU',
        'Stuttgart': 'DEU', 'DÃ¼sseldorf': 'DEU', 'Dortmund': 'DEU', 'Essen': 'DEU', 'Leipzig': 'DEU',
        'Paris': 'FRA', 'Marseille': 'FRA', 'Lyon': 'FRA', 'Toulouse': 'FRA', 'Nice': 'FRA',
        'Nantes': 'FRA', 'Strasbourg': 'FRA', 'Montpellier': 'FRA', 'Bordeaux': 'FRA', 'Lille': 'FRA',
        'Toronto': 'CAN', 'Montreal': 'CAN', 'Vancouver': 'CAN', 'Calgary': 'CAN', 'Edmonton': 'CAN',
        'Ottawa': 'CAN', 'Winnipeg': 'CAN', 'Quebec City': 'CAN', 'Hamilton': 'CAN', 'Kitchener': 'CAN',
        'Sydney': 'AUS', 'Melbourne': 'AUS', 'Brisbane': 'AUS', 'Perth': 'AUS', 'Adelaide': 'AUS',
        'Gold Coast': 'AUS', 'Newcastle': 'AUS', 'Canberra': 'AUS', 'Sunshine Coast': 'AUS', 'Wollongong': 'AUS',
        'SÃ£o Paulo': 'BRA', 'Rio de Janeiro': 'BRA', 'BrasÃ­lia': 'BRA', 'Salvador': 'BRA', 'Fortaleza': 'BRA',
        'Belo Horizonte': 'BRA', 'Manaus': 'BRA', 'Curitiba': 'BRA', 'Recife': 'BRA', 'Porto Alegre': 'BRA',
        'Johannesburg': 'ZAR', 'Cape Town': 'ZAR', 'Durban': 'ZAR', 'Pretoria': 'ZAR', 'Port Elizabeth': 'ZAR',
        'Bloemfontein': 'ZAR', 'East London': 'ZAR', 'Kimberley': 'ZAR', 'Nelspruit': 'ZAR', 'Polokwane': 'ZAR'
    }
    
    demand['country'] = demand['city'].map(country_map)
    
    print(f"âœ… ìˆ˜ìš” ë°ì´í„°: {len(demand):,}í–‰")
    print(f"âœ… ë§ˆì¼€íŒ… ë°ì´í„°: {len(marketing):,}í–‰")
    
    return demand, marketing

def analyze_marketing_demand_correlation(demand, marketing):
    """ë§ˆì¼€íŒ… ì§€ì¶œê³¼ ìˆ˜ìš”ì˜ ìƒê´€ê´€ê³„ ë¶„ì„"""
    print("\nğŸ” ë§ˆì¼€íŒ… ì§€ì¶œê³¼ ìˆ˜ìš” ìƒê´€ê´€ê³„ ë¶„ì„ ì¤‘...")
    
    # 1. êµ­ê°€ë³„ ì¼ë³„ ë§ˆì¼€íŒ… ì§€ì¶œ ì§‘ê³„
    marketing_daily = marketing.groupby(['date', 'country'])['spend_usd'].sum().reset_index()
    
    # 2. êµ­ê°€ë³„ ì¼ë³„ ìˆ˜ìš” ì§‘ê³„
    demand_daily = demand.groupby(['date', 'country'])['demand'].sum().reset_index()
    
    # 3. ë§ˆì¼€íŒ…ê³¼ ìˆ˜ìš” ë°ì´í„° ë³‘í•©
    merged_data = demand_daily.merge(marketing_daily, on=['date', 'country'], how='left')
    merged_data['spend_usd'] = merged_data['spend_usd'].fillna(0)
    
    print(f"âœ… ë³‘í•©ëœ ë°ì´í„°: {len(merged_data):,}í–‰")
    
    # 4. ì „ì²´ ìƒê´€ê´€ê³„
    correlation = merged_data['demand'].corr(merged_data['spend_usd'])
    print(f"ğŸ“Š ì „ì²´ ìƒê´€ê³„ìˆ˜: {correlation:.4f}")
    
    # 5. êµ­ê°€ë³„ ìƒê´€ê´€ê³„
    country_correlations = []
    for country in merged_data['country'].unique():
        country_data = merged_data[merged_data['country'] == country]
        if len(country_data) > 10:  # ìµœì†Œ 10ê°œ ë°ì´í„° í¬ì¸íŠ¸
            corr = country_data['demand'].corr(country_data['spend_usd'])
            country_correlations.append({
                'country': country,
                'correlation': corr,
                'data_points': len(country_data)
            })
    
    country_corr_df = pd.DataFrame(country_correlations)
    country_corr_df = country_corr_df.sort_values('correlation', ascending=False)
    
    print("\nğŸ“ˆ êµ­ê°€ë³„ ìƒê´€ê³„ìˆ˜ (ìƒìœ„ 10ê°œ):")
    print(country_corr_df.head(10))
    
    return merged_data, country_corr_df

def analyze_marketing_periods_impact(demand, marketing):
    """ë§ˆì¼€íŒ… ì§€ì¶œ ê¸°ê°„ê³¼ ìˆ˜ìš” ë³€í™” ë¶„ì„"""
    print("\nğŸ¯ ë§ˆì¼€íŒ… ì§€ì¶œ ê¸°ê°„ê³¼ ìˆ˜ìš” ë³€í™” ë¶„ì„ ì¤‘...")
    
    # 1. ë§ˆì¼€íŒ… ì§€ì¶œ ê¸°ê°„ ì°¾ê¸° (ì¶œì œì ë°©ì‹)
    marketing_daily = marketing.groupby(['date', 'country'])['spend_usd'].sum().reset_index()
    
    marketing_periods = []
    
    for country in marketing_daily['country'].unique():
        country_data = marketing_daily[marketing_daily['country'] == country].sort_values('date')
        
        # ë§ˆì¼€íŒ… ì§€ì¶œì´ ìˆëŠ” ë‚ ì§œë“¤
        active_days = country_data[country_data['spend_usd'] > 0]
        
        if len(active_days) == 0:
            continue
            
        # ì—°ì†ëœ ê¸°ê°„ìœ¼ë¡œ ê·¸ë£¹í™”
        active_days['date_diff'] = active_days['date'].diff().dt.days
        active_days['period_id'] = (active_days['date_diff'] > 1).cumsum()
        
        # ê° ê¸°ê°„ë³„ ë¶„ì„
        periods = active_days.groupby('period_id').agg(
            start_date=('date', 'min'),
            end_date=('date', 'max'),
            total_spend=('spend_usd', 'sum'),
            duration_days=('date', lambda x: (x.max() - x.min()).days + 1)
        ).reset_index()
        
        for _, period in periods.iterrows():
            marketing_periods.append({
                'country': country,
                'start_date': period['start_date'],
                'end_date': period['end_date'],
                'total_spend': period['total_spend'],
                'duration_days': period['duration_days']
            })
    
    marketing_periods_df = pd.DataFrame(marketing_periods)
    
    # 2. ê° ë§ˆì¼€íŒ… ê¸°ê°„ ì „í›„ ìˆ˜ìš” ë³€í™” ë¶„ì„
    period_impacts = []
    
    for _, period in marketing_periods_df.iterrows():
        country = period['country']
        start_date = period['start_date']
        end_date = period['end_date']
        
        # í•´ë‹¹ êµ­ê°€ì˜ ìˆ˜ìš” ë°ì´í„°
        country_demand = demand[demand['country'] == country].copy()
        
        # ë§ˆì¼€íŒ… ê¸°ê°„ ì „í›„ 30ì¼ ë¹„êµ
        before_start = start_date - pd.Timedelta(days=30)
        after_end = end_date + pd.Timedelta(days=30)
        
        # ê¸°ê°„ë³„ í‰ê·  ìˆ˜ìš”
        before_demand = country_demand[
            (country_demand['date'] >= before_start) & 
            (country_demand['date'] < start_date)
        ]['demand'].mean()
        
        during_demand = country_demand[
            (country_demand['date'] >= start_date) & 
            (country_demand['date'] <= end_date)
        ]['demand'].mean()
        
        after_demand = country_demand[
            (country_demand['date'] > end_date) & 
            (country_demand['date'] <= after_end)
        ]['demand'].mean()
        
        # ë³€í™”ìœ¨ ê³„ì‚°
        during_change = (during_demand - before_demand) / before_demand if before_demand > 0 else 0
        after_change = (after_demand - before_demand) / before_demand if before_demand > 0 else 0
        
        period_impacts.append({
            'country': country,
            'start_date': start_date,
            'end_date': end_date,
            'total_spend': period['total_spend'],
            'duration_days': period['duration_days'],
            'before_demand': before_demand,
            'during_demand': during_demand,
            'after_demand': after_demand,
            'during_change_pct': during_change * 100,
            'after_change_pct': after_change * 100
        })
    
    impacts_df = pd.DataFrame(period_impacts)
    
    print(f"âœ… ë¶„ì„ëœ ë§ˆì¼€íŒ… ê¸°ê°„: {len(impacts_df)}ê°œ")
    print(f"ğŸ“Š ë§ˆì¼€íŒ… ê¸°ê°„ ì¤‘ í‰ê·  ìˆ˜ìš” ë³€í™”: {impacts_df['during_change_pct'].mean():.2f}%")
    print(f"ğŸ“Š ë§ˆì¼€íŒ… ê¸°ê°„ í›„ í‰ê·  ìˆ˜ìš” ë³€í™”: {impacts_df['after_change_pct'].mean():.2f}%")
    
    return marketing_periods_df, impacts_df

def analyze_demand_surges_without_marketing(demand, marketing):
    """ë§ˆì¼€íŒ… ì—†ì´ ìˆ˜ìš” ê¸‰ë“±ì´ ë°œìƒí•œ ê²½ìš° ë¶„ì„"""
    print("\nğŸš¨ ë§ˆì¼€íŒ… ì—†ì´ ìˆ˜ìš” ê¸‰ë“± ë°œìƒ ì¼€ì´ìŠ¤ ë¶„ì„ ì¤‘...")
    
    # 1. êµ­ê°€ë³„ ì›”ë³„ ìˆ˜ìš” ì§‘ê³„
    demand['year_month'] = demand['date'].dt.to_period('M')
    monthly_demand = demand.groupby(['country', 'year_month'])['demand'].sum().reset_index()
    
    # 2. Z-score ê¸°ë°˜ ìˆ˜ìš” ê¸‰ë“± ê°ì§€
    demand_surges = []
    
    for country in monthly_demand['country'].unique():
        country_data = monthly_demand[monthly_demand['country'] == country].copy()
        country_data = country_data.sort_values('year_month')
        
        # 12ê°œì›” ë¡¤ë§ í‰ê· ê³¼ í‘œì¤€í¸ì°¨
        country_data['demand_mean'] = country_data['demand'].rolling(window=12, min_periods=1).mean()
        country_data['demand_std'] = country_data['demand'].rolling(window=12, min_periods=1).std()
        country_data['z_score'] = (country_data['demand'] - country_data['demand_mean']) / country_data['demand_std']
        
        # Z-score > 2ì¸ ê²½ìš°ë¥¼ ìˆ˜ìš” ê¸‰ë“±ìœ¼ë¡œ ì •ì˜
        surges = country_data[country_data['z_score'] > 2]
        
        for _, surge in surges.iterrows():
            # í•´ë‹¹ ì›”ì— ë§ˆì¼€íŒ… ì§€ì¶œì´ ìˆì—ˆëŠ”ì§€ í™•ì¸
            surge_start = surge['year_month'].start_time
            surge_end = surge['year_month'].end_time
            
            country_marketing = marketing[marketing['country'] == country]
            marketing_in_period = country_marketing[
                (country_marketing['date'] >= surge_start) & 
                (country_marketing['date'] <= surge_end) &
                (country_marketing['spend_usd'] > 0)
            ]
            
            demand_surges.append({
                'country': country,
                'year_month': surge['year_month'],
                'demand': surge['demand'],
                'z_score': surge['z_score'],
                'normal_demand': surge['demand_mean'],
                'multiplier': surge['demand'] / surge['demand_mean'],
                'had_marketing': len(marketing_in_period) > 0,
                'marketing_spend': marketing_in_period['spend_usd'].sum() if len(marketing_in_period) > 0 else 0
            })
    
    surges_df = pd.DataFrame(demand_surges)
    
    print(f"âœ… ê°ì§€ëœ ìˆ˜ìš” ê¸‰ë“±: {len(surges_df)}ê°œ")
    print(f"ğŸ“Š ë§ˆì¼€íŒ…ê³¼ í•¨ê»˜ ë°œìƒí•œ ê¸‰ë“±: {len(surges_df[surges_df['had_marketing'] == True])}ê°œ")
    print(f"ğŸ“Š ë§ˆì¼€íŒ… ì—†ì´ ë°œìƒí•œ ê¸‰ë“±: {len(surges_df[surges_df['had_marketing'] == False])}ê°œ")
    
    if len(surges_df) > 0:
        print(f"ğŸ“Š ë§ˆì¼€íŒ…ê³¼ í•¨ê»˜ ë°œìƒí•œ ê¸‰ë“±ì˜ í‰ê·  ë°°ìˆ˜: {surges_df[surges_df['had_marketing'] == True]['multiplier'].mean():.2f}")
        print(f"ğŸ“Š ë§ˆì¼€íŒ… ì—†ì´ ë°œìƒí•œ ê¸‰ë“±ì˜ í‰ê·  ë°°ìˆ˜: {surges_df[surges_df['had_marketing'] == False]['multiplier'].mean():.2f}")
    
    return surges_df

def create_visualizations(merged_data, country_corr_df, impacts_df, surges_df):
    """ì‹œê°í™” ìƒì„±"""
    print("\nğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    fig.suptitle('ë§ˆì¼€íŒ… ì§€ì¶œê³¼ ìˆ˜ìš” ê¸‰ë“± ìƒê´€ê´€ê³„ ë¶„ì„', fontsize=16, fontweight='bold')
    
    # 1. ì „ì²´ ìƒê´€ê´€ê³„ ì‚°ì ë„
    ax1 = axes[0, 0]
    ax1.scatter(merged_data['spend_usd'], merged_data['demand'], alpha=0.5, s=1)
    ax1.set_xlabel('ë§ˆì¼€íŒ… ì§€ì¶œ (USD)')
    ax1.set_ylabel('ìˆ˜ìš”')
    ax1.set_title('ë§ˆì¼€íŒ… ì§€ì¶œ vs ìˆ˜ìš” (ì „ì²´)')
    ax1.grid(True, alpha=0.3)
    
    # 2. êµ­ê°€ë³„ ìƒê´€ê³„ìˆ˜
    ax2 = axes[0, 1]
    top_countries = country_corr_df.head(10)
    bars = ax2.barh(range(len(top_countries)), top_countries['correlation'])
    ax2.set_yticks(range(len(top_countries)))
    ax2.set_yticklabels(top_countries['country'])
    ax2.set_xlabel('ìƒê´€ê³„ìˆ˜')
    ax2.set_title('êµ­ê°€ë³„ ë§ˆì¼€íŒ…-ìˆ˜ìš” ìƒê´€ê³„ìˆ˜ (ìƒìœ„ 10ê°œ)')
    ax2.grid(True, alpha=0.3)
    
    # ìƒ‰ìƒ êµ¬ë¶„ (ì–‘ì˜ ìƒê´€ê´€ê³„ vs ìŒì˜ ìƒê´€ê´€ê³„)
    for i, bar in enumerate(bars):
        if top_countries.iloc[i]['correlation'] > 0:
            bar.set_color('green')
        else:
            bar.set_color('red')
    
    # 3. ë§ˆì¼€íŒ… ê¸°ê°„ ì¤‘ ìˆ˜ìš” ë³€í™”
    ax3 = axes[1, 0]
    ax3.hist(impacts_df['during_change_pct'], bins=20, alpha=0.7, color='blue')
    ax3.axvline(impacts_df['during_change_pct'].mean(), color='red', linestyle='--', 
                label=f'í‰ê· : {impacts_df["during_change_pct"].mean():.1f}%')
    ax3.set_xlabel('ìˆ˜ìš” ë³€í™”ìœ¨ (%)')
    ax3.set_ylabel('ë¹ˆë„')
    ax3.set_title('ë§ˆì¼€íŒ… ê¸°ê°„ ì¤‘ ìˆ˜ìš” ë³€í™” ë¶„í¬')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. ë§ˆì¼€íŒ… ìœ ë¬´ì— ë”°ë¥¸ ìˆ˜ìš” ê¸‰ë“± ë¹„êµ
    ax4 = axes[1, 1]
    if len(surges_df) > 0:
        marketing_surges = surges_df[surges_df['had_marketing'] == True]['multiplier']
        no_marketing_surges = surges_df[surges_df['had_marketing'] == False]['multiplier']
        
        if len(marketing_surges) > 0 and len(no_marketing_surges) > 0:
            ax4.boxplot([marketing_surges, no_marketing_surges], 
                       labels=['ë§ˆì¼€íŒ… ìˆìŒ', 'ë§ˆì¼€íŒ… ì—†ìŒ'])
            ax4.set_ylabel('ìˆ˜ìš” ë°°ìˆ˜')
            ax4.set_title('ë§ˆì¼€íŒ… ìœ ë¬´ì— ë”°ë¥¸ ìˆ˜ìš” ê¸‰ë“± ê°•ë„ ë¹„êµ')
            ax4.grid(True, alpha=0.3)
        else:
            ax4.text(0.5, 0.5, 'ë°ì´í„° ë¶€ì¡±', ha='center', va='center', transform=ax4.transAxes)
            ax4.set_title('ë§ˆì¼€íŒ… ìœ ë¬´ì— ë”°ë¥¸ ìˆ˜ìš” ê¸‰ë“± ë¹„êµ')
    else:
        ax4.text(0.5, 0.5, 'ìˆ˜ìš” ê¸‰ë“± ë°ì´í„° ì—†ìŒ', ha='center', va='center', transform=ax4.transAxes)
        ax4.set_title('ë§ˆì¼€íŒ… ìœ ë¬´ì— ë”°ë¥¸ ìˆ˜ìš” ê¸‰ë“± ë¹„êµ')
    
    plt.tight_layout()
    plt.savefig(DATA_DIR / 'marketing_demand_correlation_analysis.png', dpi=300, bbox_inches='tight')
    print(f"âœ… ì‹œê°í™” ì €ì¥: {DATA_DIR / 'marketing_demand_correlation_analysis.png'}")
    plt.close()

def generate_summary_report(merged_data, country_corr_df, impacts_df, surges_df):
    """ë¶„ì„ ê²°ê³¼ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±"""
    print("\nğŸ“‹ ë¶„ì„ ê²°ê³¼ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
    
    # ì „ì²´ ìƒê´€ê³„ìˆ˜
    overall_corr = merged_data['demand'].corr(merged_data['spend_usd'])
    
    # ë§ˆì¼€íŒ… ê¸°ê°„ ì¤‘ ìˆ˜ìš” ë³€í™” í†µê³„
    positive_impacts = impacts_df[impacts_df['during_change_pct'] > 0]
    negative_impacts = impacts_df[impacts_df['during_change_pct'] < 0]
    
    # ìˆ˜ìš” ê¸‰ë“± í†µê³„
    marketing_surges = surges_df[surges_df['had_marketing'] == True] if len(surges_df) > 0 else pd.DataFrame()
    no_marketing_surges = surges_df[surges_df['had_marketing'] == False] if len(surges_df) > 0 else pd.DataFrame()
    
    report = f"""
# ë§ˆì¼€íŒ… ì§€ì¶œê³¼ ìˆ˜ìš” ê¸‰ë“± ìƒê´€ê´€ê³„ ë¶„ì„ ë¦¬í¬íŠ¸

## ğŸ“Š ì „ì²´ ìƒê´€ê´€ê³„
- **ì „ì²´ ìƒê´€ê³„ìˆ˜**: {overall_corr:.4f}
- **í•´ì„**: {'ê°•í•œ ì–‘ì˜ ìƒê´€ê´€ê³„' if overall_corr > 0.7 else 'ì¤‘ê°„ ì–‘ì˜ ìƒê´€ê´€ê³„' if overall_corr > 0.3 else 'ì•½í•œ ì–‘ì˜ ìƒê´€ê´€ê³„' if overall_corr > 0.1 else 'ì•½í•œ ìŒì˜ ìƒê´€ê´€ê³„' if overall_corr > -0.1 else 'ì¤‘ê°„ ìŒì˜ ìƒê´€ê´€ê³„' if overall_corr > -0.3 else 'ê°•í•œ ìŒì˜ ìƒê´€ê´€ê³„'}

## ğŸ¯ ë§ˆì¼€íŒ… ê¸°ê°„ ì¤‘ ìˆ˜ìš” ë³€í™” ë¶„ì„
- **ë¶„ì„ëœ ë§ˆì¼€íŒ… ê¸°ê°„**: {len(impacts_df)}ê°œ
- **í‰ê·  ìˆ˜ìš” ë³€í™”**: {impacts_df['during_change_pct'].mean():.2f}%
- **ìˆ˜ìš” ì¦ê°€í•œ ê¸°ê°„**: {len(positive_impacts)}ê°œ ({len(positive_impacts)/len(impacts_df)*100:.1f}%)
- **ìˆ˜ìš” ê°ì†Œí•œ ê¸°ê°„**: {len(negative_impacts)}ê°œ ({len(negative_impacts)/len(impacts_df)*100:.1f}%)

## ğŸš¨ ìˆ˜ìš” ê¸‰ë“± ë¶„ì„
- **ì´ ìˆ˜ìš” ê¸‰ë“±**: {len(surges_df)}ê°œ
- **ë§ˆì¼€íŒ…ê³¼ í•¨ê»˜ ë°œìƒ**: {len(marketing_surges)}ê°œ ({(len(marketing_surges)/len(surges_df)*100) if len(surges_df) > 0 else 0:.1f}%)
- **ë§ˆì¼€íŒ… ì—†ì´ ë°œìƒ**: {len(no_marketing_surges)}ê°œ ({(len(no_marketing_surges)/len(surges_df)*100) if len(surges_df) > 0 else 0:.1f}%)

## ğŸ“ˆ ìƒê´€ê³„ìˆ˜ ìƒìœ„ êµ­ê°€ (ìƒìœ„ 5ê°œ)
"""
    
    for i, row in country_corr_df.head(5).iterrows():
        report += f"- **{row['country']}**: {row['correlation']:.4f}\n"
    
    report += f"""
## ğŸ¯ ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­

### ì¶œì œì ê°€ì • ê²€ì¦ ê²°ê³¼
1. **ë§ˆì¼€íŒ… ì§€ì¶œê³¼ ìˆ˜ìš”ì˜ ìƒê´€ê´€ê³„**: {overall_corr:.4f} ({'ê°•í•¨' if abs(overall_corr) > 0.5 else 'ì¤‘ê°„' if abs(overall_corr) > 0.3 else 'ì•½í•¨'})
2. **ë§ˆì¼€íŒ… ê¸°ê°„ ì¤‘ ìˆ˜ìš” ë³€í™”**: {impacts_df['during_change_pct'].mean():.2f}% ({'ê¸ì •ì ' if impacts_df['during_change_pct'].mean() > 0 else 'ë¶€ì •ì '})
3. **ìˆ˜ìš” ê¸‰ë“±ê³¼ ë§ˆì¼€íŒ…ì˜ ì—°ê´€ì„±**: {(len(marketing_surges)/len(surges_df)*100) if len(surges_df) > 0 else 0:.1f}% ({'ë†’ìŒ' if len(marketing_surges)/len(surges_df) > 0.7 else 'ì¤‘ê°„' if len(marketing_surges)/len(surges_df) > 0.5 else 'ë‚®ìŒ' if len(surges_df) > 0 else 'ë°ì´í„° ì—†ìŒ'})

### ê¶Œì¥ì‚¬í•­
"""
    
    if overall_corr > 0.3:
        report += "- âœ… ë§ˆì¼€íŒ… ì§€ì¶œì„ ì´ë²¤íŠ¸ ì§€í‘œë¡œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ íƒ€ë‹¹í•¨\n"
    else:
        report += "- âš ï¸ ë§ˆì¼€íŒ… ì§€ì¶œê³¼ ìˆ˜ìš”ì˜ ìƒê´€ê´€ê³„ê°€ ì•½í•¨ - ë‹¤ë¥¸ ì§€í‘œ ê³ ë ¤ í•„ìš”\n"
    
    if impacts_df['during_change_pct'].mean() > 0:
        report += "- âœ… ë§ˆì¼€íŒ… ê¸°ê°„ ì¤‘ ìˆ˜ìš”ê°€ ì¦ê°€í•˜ëŠ” ê²½í–¥ì´ ìˆìŒ\n"
    else:
        report += "- âš ï¸ ë§ˆì¼€íŒ… ê¸°ê°„ ì¤‘ ìˆ˜ìš”ê°€ ê°ì†Œí•˜ëŠ” ê²½í–¥ì´ ìˆìŒ\n"
    
    if len(surges_df) > 0 and len(marketing_surges)/len(surges_df) > 0.5:
        report += "- âœ… ìˆ˜ìš” ê¸‰ë“±ì˜ ëŒ€ë¶€ë¶„ì´ ë§ˆì¼€íŒ…ê³¼ ì—°ê´€ë¨\n"
    else:
        report += "- âš ï¸ ìˆ˜ìš” ê¸‰ë“±ì˜ ìƒë‹¹ ë¶€ë¶„ì´ ë§ˆì¼€íŒ…ê³¼ ë¬´ê´€í•¨ - ë‹¤ë¥¸ ìš”ì¸ ê³ ë ¤ í•„ìš”\n"
    
    # ë¦¬í¬íŠ¸ ì €ì¥
    with open(DATA_DIR / 'marketing_demand_analysis_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥: {DATA_DIR / 'marketing_demand_analysis_report.md'}")
    
    return report

def main():
    """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
    print("ğŸš€ ë§ˆì¼€íŒ… ì§€ì¶œê³¼ ìˆ˜ìš” ê¸‰ë“± ìƒê´€ê´€ê³„ ë¶„ì„ ì‹œì‘")
    print("=" * 60)
    
    # 1. ë°ì´í„° ë¡œë“œ
    demand, marketing = load_data()
    
    # 2. ìƒê´€ê´€ê³„ ë¶„ì„
    merged_data, country_corr_df = analyze_marketing_demand_correlation(demand, marketing)
    
    # 3. ë§ˆì¼€íŒ… ê¸°ê°„ ì˜í–¥ ë¶„ì„
    marketing_periods_df, impacts_df = analyze_marketing_periods_impact(demand, marketing)
    
    # 4. ìˆ˜ìš” ê¸‰ë“± ë¶„ì„
    surges_df = analyze_demand_surges_without_marketing(demand, marketing)
    
    # 5. ì‹œê°í™”
    create_visualizations(merged_data, country_corr_df, impacts_df, surges_df)
    
    # 6. ë¦¬í¬íŠ¸ ìƒì„±
    report = generate_summary_report(merged_data, country_corr_df, impacts_df, surges_df)
    
    print("\n" + "=" * 60)
    print("âœ… ë§ˆì¼€íŒ… ì§€ì¶œê³¼ ìˆ˜ìš” ê¸‰ë“± ìƒê´€ê´€ê³„ ë¶„ì„ ì™„ë£Œ!")
    print("\nğŸ“‹ ì£¼ìš” ê²°ê³¼:")
    print(f"   - ì „ì²´ ìƒê´€ê³„ìˆ˜: {merged_data['demand'].corr(merged_data['spend_usd']):.4f}")
    print(f"   - ë§ˆì¼€íŒ… ê¸°ê°„ ì¤‘ í‰ê·  ìˆ˜ìš” ë³€í™”: {impacts_df['during_change_pct'].mean():.2f}%")
    if len(surges_df) > 0:
        print(f"   - ìˆ˜ìš” ê¸‰ë“± ì¤‘ ë§ˆì¼€íŒ…ê³¼ ì—°ê´€ëœ ë¹„ìœ¨: {len(surges_df[surges_df['had_marketing'] == True])/len(surges_df)*100:.1f}%")
    
    print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print(f"   - ì‹œê°í™”: {DATA_DIR / 'marketing_demand_correlation_analysis.png'}")
    print(f"   - ë¦¬í¬íŠ¸: {DATA_DIR / 'marketing_demand_analysis_report.md'}")

if __name__ == "__main__":
    main() 